# ğŸ” RAG Project - Retrieval Augmented Generation

Sistema RAG (Retrieval Augmented Generation) construido con FastAPI, LangChain y Google Gemini para responder preguntas basÃ¡ndose en documentos.

## ğŸ“‹ CaracterÃ­sticas

- **Ingesta de documentos**: Soporta PDF, TXT y DOCX
- **VectorizaciÃ³n**: Embeddings con Google Gemini (`text-embedding-004`)
- **Base vectorial**: ChromaDB para almacenamiento y bÃºsqueda
- **GeneraciÃ³n**: Respuestas con Google Gemini 2.0 Flash
- **API REST**: Endpoints documentados con Swagger/OpenAPI

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Documentos â”‚â”€â”€â”€â–¶â”‚   Chunking  â”‚â”€â”€â”€â–¶â”‚  Embeddings â”‚
â”‚  PDF/TXT/   â”‚    â”‚  (800 chars)â”‚    â”‚   (Gemini)  â”‚
â”‚    DOCX     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
                                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Respuesta  â”‚â—€â”€â”€â”€â”‚   Gemini    â”‚â—€â”€â”€â”€â”‚  ChromaDB   â”‚
â”‚   + Citas   â”‚    â”‚  2.0 Flash  â”‚    â”‚  (Vectors)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/patriciodunstan/RAGproyect.git
cd RAGproyect
```

### 2. Crear entorno virtual
```bash
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno
Crear archivo `.env` en la raÃ­z:
```env
GOOGLE_API_KEY=tu_api_key_de_google
GEMINI_MODEL=gemini-2.0-flash-exp
GEMINI_EMBED_MODEL=text-embedding-004
CHUNK_SIZE=800
CHUNK_OVERLAP=150
```

> ğŸ’¡ ObtÃ©n tu API key en: https://aistudio.google.com/app/apikey

### 5. Ejecutar el servidor
```bash
.\venv\Scripts\activate; uvicorn app.main:app --reload
```

## ğŸ“¡ API Endpoints

### DocumentaciÃ³n interactiva
- **Swagger UI**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc

### Endpoints disponibles

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| `GET` | `/` | Health check |
| `POST` | `/ingest/upload` | Subir y procesar documentos |
| `POST` | `/query/ask` | Hacer preguntas al RAG |

### Ejemplo de uso

#### Subir documento
```bash
curl -X POST "http://127.0.0.1:8000/ingest/upload" \
  -F "file=@documento.pdf"
```

#### Hacer una consulta
```bash
curl -X POST "http://127.0.0.1:8000/query/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "Â¿QuÃ© dice el documento?", "top_k": 3}'
```

#### Respuesta ejemplo
```json
{
  "answer": "SegÃºn el documento...",
  "source": [
    {
      "filename": "documento.pdf",
      "chunk_id": 0,
      "content_preview": "Texto del chunk..."
    }
  ],
  "chunk_used": 3
}
```

## ğŸ“ Estructura del Proyecto

```
RAGproyect/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app principal
â”‚   â”œâ”€â”€ config.py            # ConfiguraciÃ³n y settings
â”‚   â”œâ”€â”€ dependencies.py      # InyecciÃ³n de dependencias
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ ingest.py        # Endpoint de ingesta
â”‚   â”‚   â””â”€â”€ query.py         # Endpoint de consultas
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ loader.py        # Carga de documentos
â”‚   â”‚   â”œâ”€â”€ splitter.py      # DivisiÃ³n en chunks
â”‚   â”‚   â””â”€â”€ embedder.py      # GeneraciÃ³n de embeddings
â”‚   â””â”€â”€ retrieval/
â”‚       â”œâ”€â”€ vectorstore.py   # GestiÃ³n de ChromaDB
â”‚       â””â”€â”€ retriever.py     # RecuperaciÃ³n de contexto
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py           # Schemas Pydantic
â”œâ”€â”€ data/                    # Documentos subidos
â”œâ”€â”€ vector_db/               # Base de datos vectorial
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ azure-pipelines.yml
â””â”€â”€ README.md
```

## ğŸ› ï¸ TecnologÃ­as

| Componente | TecnologÃ­a |
|------------|------------|
| **Framework** | FastAPI |
| **LLM** | Google Gemini 2.0 Flash |
| **Embeddings** | Google Gemini `text-embedding-004` |
| **Vector Store** | ChromaDB |
| **OrquestaciÃ³n** | LangChain |
| **ValidaciÃ³n** | Pydantic |

## âš™ï¸ ConfiguraciÃ³n

| Variable | DescripciÃ³n | Default |
|----------|-------------|---------|
| `GOOGLE_API_KEY` | API key de Google AI | (requerido) |
| `GEMINI_MODEL` | Modelo para generaciÃ³n | `gemini-2.0-flash-exp` |
| `GEMINI_EMBED_MODEL` | Modelo para embeddings | `text-embedding-004` |
| `CHUNK_SIZE` | TamaÃ±o de chunks | `800` |
| `CHUNK_OVERLAP` | Solapamiento entre chunks | `150` |

## ğŸ³ Docker

```bash
docker build -t rag-project .
docker run -p 8000:8000 --env-file .env rag-project
```

## ğŸ“ Licencia

MIT License

## ğŸ‘¤ Autor

**Patricio Dunstan**
- GitHub: [@patriciodunstan](https://github.com/patriciodunstan)